<div class="txtcont">
													
													
													<p><a rel="nofollow" href="https://www.newsmth.net/nForum/#!article/Python/152831" target="_blank">https://www.newsmth.net/nForum/#!article/Python/152831</a></p> 
<p>#&nbsp;-*- coding: utf-8 -*-<br>import os<br>import requests<br>from lxml import html<br>&nbsp;&nbsp;&nbsp;&nbsp;<br>headers =&nbsp;{<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'Host':&nbsp;'m.newsmth.net',<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'Accept-Language':&nbsp;'zh-CN,zh;q=0.8,en;q=0.6',<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'Connection':&nbsp;'keep-alive',<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'Pragma':&nbsp;'no-cache',<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'Cache-Control':&nbsp;'no-cache',<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'Upgrade-Insecure-Requests':&nbsp;'1',<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'Accept':&nbsp;'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'User-Agent':&nbsp;'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_4)&nbsp;'<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36',<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'Cookie':&nbsp;'你的cookei'<br>}<br>&nbsp;&nbsp;&nbsp;&nbsp;<br>&nbsp;&nbsp;&nbsp;&nbsp;<br>def save(text, filename='temp', path='outbox'):<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; fpath = os.path.join(path, filename)<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; with open(fpath,&nbsp;'wb') as f:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; print('output:', fpath)<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; f.write(text)<br>&nbsp;&nbsp;&nbsp;&nbsp;<br>&nbsp;&nbsp;&nbsp;&nbsp;<br>def save_letter(letter_url):<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; resp = requests.get('https://m.newsmth.net'+letter_url,headers=headers)<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; page = resp.content<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; print(page)<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; save(page,letter_url.replace('/mail/outbox/','outbox')+'.html')<br>&nbsp;&nbsp;&nbsp;&nbsp;<br>def crawl(url, outbox):<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; resp = requests.get(url, headers=headers)<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; page = resp.content<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; root = html.fromstring(page)<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; letters = root.xpath('//li/a//@href')<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;# print(page.decode())<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; for letter in letters :<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if letter not in outbox and (letter.find('mail')&nbsp;&gt; 0):<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; outbox.append(letter)<br>&nbsp;&nbsp;&nbsp;&nbsp;<br>&nbsp;&nbsp;&nbsp;&nbsp;<br>if __name__ ==&nbsp;'__main__':<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#&nbsp;注意在运行之前，先确保该文件的同路径下存在一个download的文件夹,&nbsp;用于存放爬虫下载的邮件<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; obox =&nbsp;[]&nbsp;&nbsp;&nbsp;&nbsp;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; p=1<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; while(p&lt;96):&nbsp;#如果用4p只得到40结果，用96p得到64个。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; url =&nbsp;'https://m.newsmth.net/mail/outbox?p='+ str(p)&nbsp;&nbsp;&nbsp;&nbsp;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; crawl(url, obox)<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; p=p+1<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#print(obox)<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; for letter in obox :<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; save_letter(letter)<br></p>
													
												</div>